{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install vaderSentiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras import models\n",
    "from keras import layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1=pd.read_csv(\"Tweet.csv\")\n",
    "data2=pd.read_csv(\"Company_Tweet.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>writer</th>\n",
       "      <th>post_date</th>\n",
       "      <th>body</th>\n",
       "      <th>comment_num</th>\n",
       "      <th>retweet_num</th>\n",
       "      <th>like_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>550441509175443456</td>\n",
       "      <td>VisualStockRSRC</td>\n",
       "      <td>1420070457</td>\n",
       "      <td>lx21 made $10,008  on $AAPL -Check it out! htt...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>550441672312512512</td>\n",
       "      <td>KeralaGuy77</td>\n",
       "      <td>1420070496</td>\n",
       "      <td>Insanity of today weirdo massive selling. $aap...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>550441732014223360</td>\n",
       "      <td>DozenStocks</td>\n",
       "      <td>1420070510</td>\n",
       "      <td>S&amp;P100 #Stocks Performance $HD $LOW $SBUX $TGT...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>550442977802207232</td>\n",
       "      <td>ShowDreamCar</td>\n",
       "      <td>1420070807</td>\n",
       "      <td>$GM $TSLA: Volkswagen Pushes 2014 Record Recal...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>550443807834402816</td>\n",
       "      <td>i_Know_First</td>\n",
       "      <td>1420071005</td>\n",
       "      <td>Swing Trading: Up To 8.91% Return In 14 Days h...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3717959</th>\n",
       "      <td>1212159765914079234</td>\n",
       "      <td>TEEELAZER</td>\n",
       "      <td>1577836383</td>\n",
       "      <td>That $SPY $SPX puuump in the last hour was the...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3717960</th>\n",
       "      <td>1212159838882533376</td>\n",
       "      <td>ShortingIsFun</td>\n",
       "      <td>1577836401</td>\n",
       "      <td>In 2020 I may start Tweeting out positive news...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3717961</th>\n",
       "      <td>1212160015332728833</td>\n",
       "      <td>Commuternyc</td>\n",
       "      <td>1577836443</td>\n",
       "      <td>Patiently Waiting for the no twitter sitter tw...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3717962</th>\n",
       "      <td>1212160410692046849</td>\n",
       "      <td>MoriaCrypto</td>\n",
       "      <td>1577836537</td>\n",
       "      <td>I don't discriminate. I own both $aapl and $ms...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3717963</th>\n",
       "      <td>1212160477159206912</td>\n",
       "      <td>treabase</td>\n",
       "      <td>1577836553</td>\n",
       "      <td>$AAPL #patent 10,522,475 Vertical interconnect...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3717964 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    tweet_id           writer   post_date  \\\n",
       "0         550441509175443456  VisualStockRSRC  1420070457   \n",
       "1         550441672312512512      KeralaGuy77  1420070496   \n",
       "2         550441732014223360      DozenStocks  1420070510   \n",
       "3         550442977802207232     ShowDreamCar  1420070807   \n",
       "4         550443807834402816     i_Know_First  1420071005   \n",
       "...                      ...              ...         ...   \n",
       "3717959  1212159765914079234        TEEELAZER  1577836383   \n",
       "3717960  1212159838882533376    ShortingIsFun  1577836401   \n",
       "3717961  1212160015332728833      Commuternyc  1577836443   \n",
       "3717962  1212160410692046849      MoriaCrypto  1577836537   \n",
       "3717963  1212160477159206912         treabase  1577836553   \n",
       "\n",
       "                                                      body  comment_num  \\\n",
       "0        lx21 made $10,008  on $AAPL -Check it out! htt...            0   \n",
       "1        Insanity of today weirdo massive selling. $aap...            0   \n",
       "2        S&P100 #Stocks Performance $HD $LOW $SBUX $TGT...            0   \n",
       "3        $GM $TSLA: Volkswagen Pushes 2014 Record Recal...            0   \n",
       "4        Swing Trading: Up To 8.91% Return In 14 Days h...            0   \n",
       "...                                                    ...          ...   \n",
       "3717959  That $SPY $SPX puuump in the last hour was the...            1   \n",
       "3717960  In 2020 I may start Tweeting out positive news...            0   \n",
       "3717961  Patiently Waiting for the no twitter sitter tw...            0   \n",
       "3717962  I don't discriminate. I own both $aapl and $ms...            1   \n",
       "3717963  $AAPL #patent 10,522,475 Vertical interconnect...            0   \n",
       "\n",
       "         retweet_num  like_num  \n",
       "0                  0         1  \n",
       "1                  0         0  \n",
       "2                  0         0  \n",
       "3                  0         1  \n",
       "4                  0         1  \n",
       "...              ...       ...  \n",
       "3717959            0         6  \n",
       "3717960            0         1  \n",
       "3717961            0         5  \n",
       "3717962            0         1  \n",
       "3717963            0         0  \n",
       "\n",
       "[3717964 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>ticker_symbol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>550803612197457920</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>550803610825928706</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>550803225113157632</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>550802957370159104</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>550802855129382912</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4336440</th>\n",
       "      <td>1212158772015034369</td>\n",
       "      <td>TSLA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4336441</th>\n",
       "      <td>1212159099632267268</td>\n",
       "      <td>TSLA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4336442</th>\n",
       "      <td>1212159184931717120</td>\n",
       "      <td>TSLA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4336443</th>\n",
       "      <td>1212159838882533376</td>\n",
       "      <td>TSLA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4336444</th>\n",
       "      <td>1212160015332728833</td>\n",
       "      <td>TSLA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4336445 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    tweet_id ticker_symbol\n",
       "0         550803612197457920          AAPL\n",
       "1         550803610825928706          AAPL\n",
       "2         550803225113157632          AAPL\n",
       "3         550802957370159104          AAPL\n",
       "4         550802855129382912          AAPL\n",
       "...                      ...           ...\n",
       "4336440  1212158772015034369          TSLA\n",
       "4336441  1212159099632267268          TSLA\n",
       "4336442  1212159184931717120          TSLA\n",
       "4336443  1212159838882533376          TSLA\n",
       "4336444  1212160015332728833          TSLA\n",
       "\n",
       "[4336445 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performing EDA on Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3717964, 7)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140132"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data1['writer'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet_id           0\n",
       "writer         47273\n",
       "post_date          0\n",
       "body               0\n",
       "comment_num        0\n",
       "retweet_num        0\n",
       "like_num           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet_id         0\n",
       "ticker_symbol    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.merge(data2, data1, on='tweet_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4336445, 8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>ticker_symbol</th>\n",
       "      <th>writer</th>\n",
       "      <th>post_date</th>\n",
       "      <th>body</th>\n",
       "      <th>comment_num</th>\n",
       "      <th>retweet_num</th>\n",
       "      <th>like_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>550803612197457920</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>SentiQuant</td>\n",
       "      <td>1420156789</td>\n",
       "      <td>#TOPTICKERTWEETS $AAPL $IMRS $BABA $EBAY $AMZN...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>550803612197457920</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>SentiQuant</td>\n",
       "      <td>1420156789</td>\n",
       "      <td>#TOPTICKERTWEETS $AAPL $IMRS $BABA $EBAY $AMZN...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>550803610825928706</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>SentiQuant</td>\n",
       "      <td>1420156788</td>\n",
       "      <td>#SENTISHIFTUP $K $FB $GOOGL $GS $GOLD $T $AAPL...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>550803610825928706</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>SentiQuant</td>\n",
       "      <td>1420156788</td>\n",
       "      <td>#SENTISHIFTUP $K $FB $GOOGL $GS $GOLD $T $AAPL...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>550803610825928706</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>SentiQuant</td>\n",
       "      <td>1420156788</td>\n",
       "      <td>#SENTISHIFTUP $K $FB $GOOGL $GS $GOLD $T $AAPL...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4336440</th>\n",
       "      <td>1212158772015034369</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>StockJoke</td>\n",
       "      <td>1577836146</td>\n",
       "      <td>I'm getting wasted on NYE, and thanks to @NHTS...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4336441</th>\n",
       "      <td>1212159099632267268</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>sweetog76</td>\n",
       "      <td>1577836224</td>\n",
       "      <td>$TSLA Very Interesting dude:</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4336442</th>\n",
       "      <td>1212159184931717120</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>MelaynaLokosky</td>\n",
       "      <td>1577836245</td>\n",
       "      <td>If only 2020 brought more self-awareness to Te...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4336443</th>\n",
       "      <td>1212159838882533376</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>ShortingIsFun</td>\n",
       "      <td>1577836401</td>\n",
       "      <td>In 2020 I may start Tweeting out positive news...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4336444</th>\n",
       "      <td>1212160015332728833</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>Commuternyc</td>\n",
       "      <td>1577836443</td>\n",
       "      <td>Patiently Waiting for the no twitter sitter tw...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4336445 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    tweet_id ticker_symbol          writer   post_date  \\\n",
       "0         550803612197457920          AAPL      SentiQuant  1420156789   \n",
       "1         550803612197457920          AMZN      SentiQuant  1420156789   \n",
       "2         550803610825928706          AAPL      SentiQuant  1420156788   \n",
       "3         550803610825928706         GOOGL      SentiQuant  1420156788   \n",
       "4         550803610825928706          AMZN      SentiQuant  1420156788   \n",
       "...                      ...           ...             ...         ...   \n",
       "4336440  1212158772015034369          TSLA       StockJoke  1577836146   \n",
       "4336441  1212159099632267268          TSLA       sweetog76  1577836224   \n",
       "4336442  1212159184931717120          TSLA  MelaynaLokosky  1577836245   \n",
       "4336443  1212159838882533376          TSLA   ShortingIsFun  1577836401   \n",
       "4336444  1212160015332728833          TSLA     Commuternyc  1577836443   \n",
       "\n",
       "                                                      body  comment_num  \\\n",
       "0        #TOPTICKERTWEETS $AAPL $IMRS $BABA $EBAY $AMZN...            0   \n",
       "1        #TOPTICKERTWEETS $AAPL $IMRS $BABA $EBAY $AMZN...            0   \n",
       "2        #SENTISHIFTUP $K $FB $GOOGL $GS $GOLD $T $AAPL...            0   \n",
       "3        #SENTISHIFTUP $K $FB $GOOGL $GS $GOLD $T $AAPL...            0   \n",
       "4        #SENTISHIFTUP $K $FB $GOOGL $GS $GOLD $T $AAPL...            0   \n",
       "...                                                    ...          ...   \n",
       "4336440  I'm getting wasted on NYE, and thanks to @NHTS...            0   \n",
       "4336441                       $TSLA Very Interesting dude:            0   \n",
       "4336442  If only 2020 brought more self-awareness to Te...            0   \n",
       "4336443  In 2020 I may start Tweeting out positive news...            0   \n",
       "4336444  Patiently Waiting for the no twitter sitter tw...            0   \n",
       "\n",
       "         retweet_num  like_num  \n",
       "0                  0         1  \n",
       "1                  0         1  \n",
       "2                  0         1  \n",
       "3                  0         1  \n",
       "4                  0         1  \n",
       "...              ...       ...  \n",
       "4336440            0         0  \n",
       "4336441            0         0  \n",
       "4336442            1         0  \n",
       "4336443            0         1  \n",
       "4336444            0         5  \n",
       "\n",
       "[4336445 rows x 8 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet_id             0\n",
       "ticker_symbol        0\n",
       "writer           55919\n",
       "post_date            0\n",
       "body                 0\n",
       "comment_num          0\n",
       "retweet_num          0\n",
       "like_num             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#TOPTICKERTWEETS $AAPL $IMRS $BABA $EBAY $AMZN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#TOPTICKERTWEETS $AAPL $IMRS $BABA $EBAY $AMZN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#SENTISHIFTUP $K $FB $GOOGL $GS $GOLD $T $AAPL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#SENTISHIFTUP $K $FB $GOOGL $GS $GOLD $T $AAPL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#SENTISHIFTUP $K $FB $GOOGL $GS $GOLD $T $AAPL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4336440</th>\n",
       "      <td>I'm getting wasted on NYE, and thanks to @NHTS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4336441</th>\n",
       "      <td>$TSLA Very Interesting dude:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4336442</th>\n",
       "      <td>If only 2020 brought more self-awareness to Te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4336443</th>\n",
       "      <td>In 2020 I may start Tweeting out positive news...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4336444</th>\n",
       "      <td>Patiently Waiting for the no twitter sitter tw...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4336445 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      body\n",
       "0        #TOPTICKERTWEETS $AAPL $IMRS $BABA $EBAY $AMZN...\n",
       "1        #TOPTICKERTWEETS $AAPL $IMRS $BABA $EBAY $AMZN...\n",
       "2        #SENTISHIFTUP $K $FB $GOOGL $GS $GOLD $T $AAPL...\n",
       "3        #SENTISHIFTUP $K $FB $GOOGL $GS $GOLD $T $AAPL...\n",
       "4        #SENTISHIFTUP $K $FB $GOOGL $GS $GOLD $T $AAPL...\n",
       "...                                                    ...\n",
       "4336440  I'm getting wasted on NYE, and thanks to @NHTS...\n",
       "4336441                       $TSLA Very Interesting dude:\n",
       "4336442  If only 2020 brought more self-awareness to Te...\n",
       "4336443  In 2020 I may start Tweeting out positive news...\n",
       "4336444  Patiently Waiting for the no twitter sitter tw...\n",
       "\n",
       "[4336445 rows x 1 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=tweets[\"body\"]\n",
    "df=pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "to_remove = ['against', 'between','into',\n",
    " 'through',\n",
    " 'during',\n",
    " 'before',\n",
    " 'after',\n",
    " 'above',\n",
    " 'below','from',\n",
    " 'up',\n",
    " 'down',\n",
    " 'in',\n",
    " 'out',\n",
    " 'on','off',\n",
    " 'over',\n",
    " 'under','few',\n",
    " 'more',\n",
    " 'most',\n",
    " 'other',\n",
    " 'some',\n",
    " 'such',\n",
    " 'no',\n",
    " 'nor',\n",
    " 'not',\n",
    " 'only',\n",
    " 'own','very']\n",
    "stopwords = set(stopwords.words('english')).difference(to_remove)\n",
    "stopwords=list(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "contractions_dict = { \"ain't\": \"are not\",\"'s\":\" is\",\"aren't\": \"are not\",\n",
    "                     \"can't\": \"cannot\",\"can't've\": \"cannot have\",\n",
    "                     \"'cause\": \"because\",\"could've\": \"could have\",\"couldn't\": \"could not\",\n",
    "                     \"couldn't've\": \"could not have\", \"didn't\": \"did not\",\"doesn't\": \"does not\",\n",
    "                     \"don't\": \"do not\",\"hadn't\": \"had not\",\"hadn't've\": \"had not have\",\n",
    "                     \"hasn't\": \"has not\",\"haven't\": \"have not\",\"he'd\": \"he would\",\n",
    "                     \"he'd've\": \"he would have\",\"he'll\": \"he will\", \"he'll've\": \"he will have\",\n",
    "                     \"how'd\": \"how did\",\"how'd'y\": \"how do you\",\"how'll\": \"how will\",\n",
    "                     \"I'd\": \"I would\", \"I'd've\": \"I would have\",\"I'll\": \"I will\",\n",
    "                     \"I'll've\": \"I will have\",\"I'm\": \"I am\",\"I've\": \"I have\", \"isn't\": \"is not\",\n",
    "                     \"it'd\": \"it would\",\"it'd've\": \"it would have\",\"it'll\": \"it will\",\n",
    "                     \"it'll've\": \"it will have\", \"let's\": \"let us\",\"ma'am\": \"madam\",\n",
    "                     \"mayn't\": \"may not\",\"might've\": \"might have\",\"mightn't\": \"might not\", \n",
    "                     \"mightn't've\": \"might not have\",\"must've\": \"must have\",\"mustn't\": \"must not\",\n",
    "                     \"mustn't've\": \"must not have\", \"needn't\": \"need not\",\n",
    "                     \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\"oughtn't\": \"ought not\",\n",
    "                     \"oughtn't've\": \"ought not have\",\"shan't\": \"shall not\",\"sha'n't\": \"shall not\",\n",
    "                     \"shan't've\": \"shall not have\",\"she'd\": \"she would\",\"she'd've\": \"she would have\",\n",
    "                     \"she'll\": \"she will\", \"she'll've\": \"she will have\",\"should've\": \"should have\",\n",
    "                     \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\",\"so've\": \"so have\",\n",
    "                     \"that'd\": \"that would\",\"that'd've\": \"that would have\", \"there'd\": \"there would\",\n",
    "                     \"there'd've\": \"there would have\", \"they'd\": \"they would\",\n",
    "                     \"they'd've\": \"they would have\",\"they'll\": \"they will\",\n",
    "                     \"they'll've\": \"they will have\", \"they're\": \"they are\",\"they've\": \"they have\",\n",
    "                     \"to've\": \"to have\",\"wasn't\": \"was not\",\"we'd\": \"we would\",\n",
    "                     \"we'd've\": \"we would have\",\"we'll\": \"we will\",\"we'll've\": \"we will have\",\n",
    "                     \"we're\": \"we are\",\"we've\": \"we have\", \"weren't\": \"were not\",\"what'll\": \"what will\",\n",
    "                     \"what'll've\": \"what will have\",\"what're\": \"what are\", \"what've\": \"what have\",\n",
    "                     \"when've\": \"when have\",\"where'd\": \"where did\", \"where've\": \"where have\",\n",
    "                     \"who'll\": \"who will\",\"who'll've\": \"who will have\",\"who've\": \"who have\",\n",
    "                     \"why've\": \"why have\",\"will've\": \"will have\",\"won't\": \"will not\",\n",
    "                     \"won't've\": \"will not have\", \"would've\": \"would have\",\"wouldn't\": \"would not\",\n",
    "                     \"wouldn't've\": \"would not have\",\"y'all\": \"you all\", \"y'all'd\": \"you all would\",\n",
    "                     \"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\n",
    "                     \"y'all've\": \"you all have\", \"you'd\": \"you would\",\"you'd've\": \"you would have\",\n",
    "                     \"you'll\": \"you will\",\"you'll've\": \"you will have\", \"you're\": \"you are\",\n",
    "                     \"you've\": \"you have\"}\n",
    "\n",
    "# Regular expression for finding contractions\n",
    "\n",
    "def expand_contractions(text,contractions_dict=contractions_dict):\n",
    "    def replace(match):\n",
    "        return contractions_dict[match.group(0)]\n",
    "    return contractions_re.sub(replace, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(x):\n",
    "    x=x.lower()\n",
    "    words = x.split()\n",
    "    words = [expand_contractions(word) for word in words]\n",
    "    translating = str.maketrans('', '', string.punctuation)\n",
    "    x=' '.join(words)\n",
    "    x = x.translate(translating)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_words(text):\n",
    "    \n",
    "    words = text.split()\n",
    "    words = [lemmatizer.lemmatize(word,pos='v') for word in words]\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    #removing all stop words is not useful\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def negativityCheck(sentence):\n",
    "    if(analyzer.polarity_scores(sentence)[\"neg\"]>0.7):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "contractions_re=re.compile('(%s)' % '|'.join(contractions_dict.keys()))\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "df[\"body\"]=df[\"body\"].apply(preprocessing)\n",
    "df['lemma'] = df['body'].apply(lemmatize_words)\n",
    "df[\"negative\"]=df[\"lemma\"].apply(negativityCheck).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>lemma</th>\n",
       "      <th>negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1119</th>\n",
       "      <td>there is that panic in aapl</td>\n",
       "      <td>panic aapl</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3643</th>\n",
       "      <td>what the fuck aapl</td>\n",
       "      <td>fuck aapl</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4967</th>\n",
       "      <td>aapl pathetic and weak</td>\n",
       "      <td>aapl pathetic weak</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4969</th>\n",
       "      <td>aapl dump</td>\n",
       "      <td>aapl dump</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5271</th>\n",
       "      <td>aapl dead cat died spy</td>\n",
       "      <td>aapl dead cat die spy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4333373</th>\n",
       "      <td>tsla killers that died before arrival</td>\n",
       "      <td>tsla killers die arrival</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4334723</th>\n",
       "      <td>nah tsla goes up on fraud</td>\n",
       "      <td>nah tsla go fraud</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4334729</th>\n",
       "      <td>tsla 410 the horror the horror</td>\n",
       "      <td>tsla 410 horror horror</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4335935</th>\n",
       "      <td>tsla  you are a crazy sob</td>\n",
       "      <td>tsla crazy sob</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4336070</th>\n",
       "      <td>tsla drop the bomb</td>\n",
       "      <td>tsla drop bomb</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2486 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          body                     lemma  \\\n",
       "1119               there is that panic in aapl                panic aapl   \n",
       "3643                        what the fuck aapl                 fuck aapl   \n",
       "4967                    aapl pathetic and weak        aapl pathetic weak   \n",
       "4969                                 aapl dump                 aapl dump   \n",
       "5271                    aapl dead cat died spy     aapl dead cat die spy   \n",
       "...                                        ...                       ...   \n",
       "4333373  tsla killers that died before arrival  tsla killers die arrival   \n",
       "4334723              nah tsla goes up on fraud         nah tsla go fraud   \n",
       "4334729         tsla 410 the horror the horror    tsla 410 horror horror   \n",
       "4335935              tsla  you are a crazy sob            tsla crazy sob   \n",
       "4336070                     tsla drop the bomb            tsla drop bomb   \n",
       "\n",
       "         negative  \n",
       "1119            1  \n",
       "3643            1  \n",
       "4967            1  \n",
       "4969            1  \n",
       "5271            1  \n",
       "...           ...  \n",
       "4333373         1  \n",
       "4334723         1  \n",
       "4334729         1  \n",
       "4335935         1  \n",
       "4336070         1  \n",
       "\n",
       "[2486 rows x 3 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"negative\"]==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"ticker_symbol\",\"comment_num\", \"retweet_num\", \"like_num\"]]=tweets[['ticker_symbol',\"comment_num\", \"retweet_num\", \"like_num\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>lemma</th>\n",
       "      <th>negative</th>\n",
       "      <th>ticker_symbol</th>\n",
       "      <th>comment_num</th>\n",
       "      <th>retweet_num</th>\n",
       "      <th>like_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>toptickertweets aapl imrs baba ebay amzn t ign...</td>\n",
       "      <td>toptickertweets aapl imrs baba ebay amzn ign s...</td>\n",
       "      <td>0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>toptickertweets aapl imrs baba ebay amzn t ign...</td>\n",
       "      <td>toptickertweets aapl imrs baba ebay amzn ign s...</td>\n",
       "      <td>0</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sentishiftup k fb googl gs gold t aapl baba tw...</td>\n",
       "      <td>sentishiftup k fb googl gs gold aapl baba twtr...</td>\n",
       "      <td>0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sentishiftup k fb googl gs gold t aapl baba tw...</td>\n",
       "      <td>sentishiftup k fb googl gs gold aapl baba twtr...</td>\n",
       "      <td>0</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sentishiftup k fb googl gs gold t aapl baba tw...</td>\n",
       "      <td>sentishiftup k fb googl gs gold aapl baba twtr...</td>\n",
       "      <td>0</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4336440</th>\n",
       "      <td>im getting wasted on nye and thanks to nhtsago...</td>\n",
       "      <td>im get waste nye thank nhtsagov approve tsla a...</td>\n",
       "      <td>0</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4336441</th>\n",
       "      <td>tsla very interesting dude</td>\n",
       "      <td>tsla interest dude</td>\n",
       "      <td>0</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4336442</th>\n",
       "      <td>if only 2020 brought more selfawareness to tes...</td>\n",
       "      <td>2020 bring selfawareness tesla autopilot assho...</td>\n",
       "      <td>0</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4336443</th>\n",
       "      <td>in 2020 i may start tweeting out positive news...</td>\n",
       "      <td>2020 may start tweet positive news xom cvx mce...</td>\n",
       "      <td>0</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4336444</th>\n",
       "      <td>patiently waiting for the no twitter sitter tw...</td>\n",
       "      <td>patiently wait twitter sitter tweet tsla tslaq</td>\n",
       "      <td>0</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4336445 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      body  \\\n",
       "0        toptickertweets aapl imrs baba ebay amzn t ign...   \n",
       "1        toptickertweets aapl imrs baba ebay amzn t ign...   \n",
       "2        sentishiftup k fb googl gs gold t aapl baba tw...   \n",
       "3        sentishiftup k fb googl gs gold t aapl baba tw...   \n",
       "4        sentishiftup k fb googl gs gold t aapl baba tw...   \n",
       "...                                                    ...   \n",
       "4336440  im getting wasted on nye and thanks to nhtsago...   \n",
       "4336441                         tsla very interesting dude   \n",
       "4336442  if only 2020 brought more selfawareness to tes...   \n",
       "4336443  in 2020 i may start tweeting out positive news...   \n",
       "4336444  patiently waiting for the no twitter sitter tw...   \n",
       "\n",
       "                                                     lemma  negative  \\\n",
       "0        toptickertweets aapl imrs baba ebay amzn ign s...         0   \n",
       "1        toptickertweets aapl imrs baba ebay amzn ign s...         0   \n",
       "2        sentishiftup k fb googl gs gold aapl baba twtr...         0   \n",
       "3        sentishiftup k fb googl gs gold aapl baba twtr...         0   \n",
       "4        sentishiftup k fb googl gs gold aapl baba twtr...         0   \n",
       "...                                                    ...       ...   \n",
       "4336440  im get waste nye thank nhtsagov approve tsla a...         0   \n",
       "4336441                                 tsla interest dude         0   \n",
       "4336442  2020 bring selfawareness tesla autopilot assho...         0   \n",
       "4336443  2020 may start tweet positive news xom cvx mce...         0   \n",
       "4336444     patiently wait twitter sitter tweet tsla tslaq         0   \n",
       "\n",
       "        ticker_symbol  comment_num  retweet_num  like_num  \n",
       "0                AAPL            0            0         1  \n",
       "1                AMZN            0            0         1  \n",
       "2                AAPL            0            0         1  \n",
       "3               GOOGL            0            0         1  \n",
       "4                AMZN            0            0         1  \n",
       "...               ...          ...          ...       ...  \n",
       "4336440          TSLA            0            0         0  \n",
       "4336441          TSLA            0            0         0  \n",
       "4336442          TSLA            0            1         0  \n",
       "4336443          TSLA            0            0         1  \n",
       "4336444          TSLA            0            0         5  \n",
       "\n",
       "[4336445 rows x 7 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ticker_symbol\n",
       "AAPL      704\n",
       "AMZN      399\n",
       "GOOG       58\n",
       "GOOGL     157\n",
       "MSFT       80\n",
       "TSLA     1088\n",
       "Name: ticker_symbol, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['negative']==1].groupby(['ticker_symbol'])[\"ticker_symbol\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2486"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['negative']==1].groupby(['ticker_symbol'])[\"ticker_symbol\"].count().sum()  #negative sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1=df[df[\"negative\"]==1]\n",
    "# randomly choosing postive tweets for our dataset\n",
    "d2=df[df[\"negative\"]==0].sample(n = 2000, random_state = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [d1, d2]\n",
    "\n",
    "data = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>lemma</th>\n",
       "      <th>negative</th>\n",
       "      <th>ticker_symbol</th>\n",
       "      <th>comment_num</th>\n",
       "      <th>retweet_num</th>\n",
       "      <th>like_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1119</th>\n",
       "      <td>there is that panic in aapl</td>\n",
       "      <td>panic aapl</td>\n",
       "      <td>1</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3643</th>\n",
       "      <td>what the fuck aapl</td>\n",
       "      <td>fuck aapl</td>\n",
       "      <td>1</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4967</th>\n",
       "      <td>aapl pathetic and weak</td>\n",
       "      <td>aapl pathetic weak</td>\n",
       "      <td>1</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4969</th>\n",
       "      <td>aapl dump</td>\n",
       "      <td>aapl dump</td>\n",
       "      <td>1</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5271</th>\n",
       "      <td>aapl dead cat died spy</td>\n",
       "      <td>aapl dead cat die spy</td>\n",
       "      <td>1</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110081</th>\n",
       "      <td>rt reuters  applewatch not on shopping list fo...</td>\n",
       "      <td>rt reuters applewatch shop list 69 percent ame...</td>\n",
       "      <td>0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2266303</th>\n",
       "      <td>lol mention googl in a tweet and start getting...</td>\n",
       "      <td>lol mention googl tweet start get add sort lis...</td>\n",
       "      <td>0</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1364889</th>\n",
       "      <td>cityfalcon score gives top rated news for free...</td>\n",
       "      <td>cityfalcon score give top rat news free bigdat...</td>\n",
       "      <td>0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4160005</th>\n",
       "      <td>rolled down to 2025s at 163 tsla</td>\n",
       "      <td>roll 2025s 163 tsla</td>\n",
       "      <td>0</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2314524</th>\n",
       "      <td>googl best fundamental rating httpbitly1i0swpi</td>\n",
       "      <td>googl best fundamental rat httpbitly1i0swpi</td>\n",
       "      <td>0</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4486 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      body  \\\n",
       "1119                           there is that panic in aapl   \n",
       "3643                                    what the fuck aapl   \n",
       "4967                                aapl pathetic and weak   \n",
       "4969                                             aapl dump   \n",
       "5271                                aapl dead cat died spy   \n",
       "...                                                    ...   \n",
       "110081   rt reuters  applewatch not on shopping list fo...   \n",
       "2266303  lol mention googl in a tweet and start getting...   \n",
       "1364889  cityfalcon score gives top rated news for free...   \n",
       "4160005                   rolled down to 2025s at 163 tsla   \n",
       "2314524     googl best fundamental rating httpbitly1i0swpi   \n",
       "\n",
       "                                                     lemma  negative  \\\n",
       "1119                                            panic aapl         1   \n",
       "3643                                             fuck aapl         1   \n",
       "4967                                    aapl pathetic weak         1   \n",
       "4969                                             aapl dump         1   \n",
       "5271                                 aapl dead cat die spy         1   \n",
       "...                                                    ...       ...   \n",
       "110081   rt reuters applewatch shop list 69 percent ame...         0   \n",
       "2266303  lol mention googl tweet start get add sort lis...         0   \n",
       "1364889  cityfalcon score give top rat news free bigdat...         0   \n",
       "4160005                                roll 2025s 163 tsla         0   \n",
       "2314524        googl best fundamental rat httpbitly1i0swpi         0   \n",
       "\n",
       "        ticker_symbol  comment_num  retweet_num  like_num  \n",
       "1119             AAPL            0            1         1  \n",
       "3643             AAPL            0            0         0  \n",
       "4967             AAPL            0            0         0  \n",
       "4969             AAPL            0            0         0  \n",
       "5271             AAPL            1            0         0  \n",
       "...               ...          ...          ...       ...  \n",
       "110081           AAPL            0            1         0  \n",
       "2266303         GOOGL            0            0         0  \n",
       "1364889          AAPL            0            0         0  \n",
       "4160005          TSLA            0            0         1  \n",
       "2314524         GOOGL            0            0         0  \n",
       "\n",
       "[4486 rows x 7 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 7.9311\n",
      "Std: 7.2590\n",
      "Mean+3*Std = 29.7083\n",
      "Max: 51.0000\n",
      "Min: 1.0000\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "lengths = data[\"lemma\"].apply(lambda x : len(x.split(\" \"))) # mean + 3*sigma\n",
    "lengths.hist()\n",
    "plt.show()\n",
    "\n",
    "mean = lengths.mean()\n",
    "std = lengths.std()\n",
    "maxn= max(lengths)\n",
    "minn= min(lengths)\n",
    "approx_nseq = mean + 3*std\n",
    "print(f\"Mean: {mean:.4f}\\nStd: {std:.4f}\\nMean+3*Std = {approx_nseq:.4f}\\nMax: {maxn:.4f}\\nMin: {minn:.4f}\")\n",
    "\n",
    "\n",
    "#Here we can find the average length of comments \n",
    "#Most of the sentence have a length of less than 10 \n",
    "#Average length of each sentence is 12\n",
    "#max length of sentence is 58 \n",
    "#min length of sentence is 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN=int(approx_nseq)\n",
    "NB_WORDS=sum(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                                                     lemma ticker_symbol  \\\n",
       " 2909584  amzn say middle finger trummmp dave alertajawe...          AMZN   \n",
       " 3814419                                        stupid tsla          TSLA   \n",
       " 2792923    invest amazon require 2020 vision vr world amzn          AMZN   \n",
       " 4249540                 block httpstwittercompaul917017636          TSLA   \n",
       " 4246841   tsla tesla desperately fight already lose battle          TSLA   \n",
       " ...                                                    ...           ...   \n",
       " 2987831  day4 spy 921 amzn 1615c 1852 amzn 1560p 490 3 ...          AMZN   \n",
       " 1004253                                   aapl crap low ah          AAPL   \n",
       " 3219465  curt kolcun microsoft seek facilitate govt clo...          MSFT   \n",
       " 3939250  tsla semi production suppose start 2019 see me...          TSLA   \n",
       " 3045327                                 amzn lose get ugly          AMZN   \n",
       " \n",
       "          comment_num  retweet_num  like_num  \n",
       " 2909584            0            0         0  \n",
       " 3814419            0            0         1  \n",
       " 2792923            0            0         0  \n",
       " 4249540            1            0         4  \n",
       " 4246841            0            0         0  \n",
       " ...              ...          ...       ...  \n",
       " 2987831            0            0         0  \n",
       " 1004253            3            3         5  \n",
       " 3219465            0            0         0  \n",
       " 3939250            1            0         1  \n",
       " 3045327            0            0         3  \n",
       " \n",
       " [3364 rows x 5 columns],\n",
       "                                                      lemma ticker_symbol  \\\n",
       " 262443                             say tvix aapl go market          AAPL   \n",
       " 3327544                                         blame msft          MSFT   \n",
       " 3659651                                          tsla ugly          TSLA   \n",
       " 4202102                                 hell tsla disagree          TSLA   \n",
       " 2988314  lol get worse rut call good miss trade support...          AMZN   \n",
       " ...                                                    ...           ...   \n",
       " 3662469                                          hurt tsla          TSLA   \n",
       " 3707334                                         worse tsla          TSLA   \n",
       " 2983210                     already 100 nov9 1500 amzn put          AMZN   \n",
       " 971186                                          loser aapl          AAPL   \n",
       " 3215248  msft report fq1 earn 76c eps 2233b rev httpest...          MSFT   \n",
       " \n",
       "          comment_num  retweet_num  like_num  \n",
       " 262443             0            0         0  \n",
       " 3327544            0            0         0  \n",
       " 3659651            0            0         1  \n",
       " 4202102            0            1         5  \n",
       " 2988314            0            0         0  \n",
       " ...              ...          ...       ...  \n",
       " 3662469            0            0         0  \n",
       " 3707334            0            0         0  \n",
       " 2983210            0            0         0  \n",
       " 971186             0            0         0  \n",
       " 3215248            0            0         0  \n",
       " \n",
       " [1122 rows x 5 columns],\n",
       " 2909584    0\n",
       " 3814419    1\n",
       " 2792923    0\n",
       " 4249540    1\n",
       " 4246841    1\n",
       "           ..\n",
       " 2987831    0\n",
       " 1004253    1\n",
       " 3219465    0\n",
       " 3939250    0\n",
       " 3045327    1\n",
       " Name: negative, Length: 3364, dtype: int64,\n",
       " 262443     0\n",
       " 3327544    1\n",
       " 3659651    1\n",
       " 4202102    1\n",
       " 2988314    0\n",
       "           ..\n",
       " 3662469    1\n",
       " 3707334    1\n",
       " 2983210    0\n",
       " 971186     1\n",
       " 3215248    0\n",
       " Name: negative, Length: 1122, dtype: int64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data[[\"lemma\",\"ticker_symbol\",\"comment_num\",\"retweet_num\",\"like_num\"]], data[\"negative\"],stratify=data[\"negative\"], test_size=0.25,random_state=2)\n",
    "X_train, X_test, y_train, y_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tk = Tokenizer()\n",
    "tk.fit_on_texts(X_train['lemma'])\n",
    "X_train_seq = tk.texts_to_sequences(X_train['lemma'])\n",
    "X_test_seq = tk.texts_to_sequences(X_test['lemma'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2909584    amzn say middle finger trummmp dave alertajawe...\n",
       "3814419                                          stupid tsla\n",
       "2792923      invest amazon require 2020 vision vr world amzn\n",
       "4249540                   block httpstwittercompaul917017636\n",
       "4246841     tsla tesla desperately fight already lose battle\n",
       "                                 ...                        \n",
       "2987831    day4 spy 921 amzn 1615c 1852 amzn 1560p 490 3 ...\n",
       "1004253                                     aapl crap low ah\n",
       "3219465    curt kolcun microsoft seek facilitate govt clo...\n",
       "3939250    tsla semi production suppose start 2019 see me...\n",
       "3045327                                   amzn lose get ugly\n",
       "Name: lemma, Length: 3364, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['lemma']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_seq_trunc = pad_sequences(X_train_seq, maxlen=MAX_LEN)\n",
    "X_test_seq_trunc = pad_sequences(X_test_seq, maxlen=MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y_train_le = le.fit_transform(y_train)\n",
    "y_test_le = le.transform(y_test)\n",
    "y_train_oh = to_categorical(y_train_le)\n",
    "y_test_oh = to_categorical(y_test_le)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_emb, X_valid_emb, y_train_emb, y_valid_emb = train_test_split(X_train_seq_trunc, y_train_oh, test_size=0.1, random_state=37)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.autograph.set_verbosity(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 29, 3000)          106737000 \n",
      "                                                                 \n",
      " spatial_dropout1d_1 (Spatia  (None, 29, 3000)         0         \n",
      " lDropout1D)                                                     \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 704)               10433280  \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 352)               248160    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2)                 706       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 117,419,146\n",
      "Trainable params: 117,419,146\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/5\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001FA8B51BC18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "95/95 [==============================] - ETA: 0s - loss: 0.1770 - accuracy: 0.9329WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001FA8C03CA68> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "95/95 [==============================] - 235s 2s/step - loss: 0.1770 - accuracy: 0.9329 - val_loss: 0.0720 - val_accuracy: 0.9733\n",
      "Epoch 2/5\n",
      "95/95 [==============================] - 238s 3s/step - loss: 0.0272 - accuracy: 0.9921 - val_loss: 0.0891 - val_accuracy: 0.9792\n",
      "Epoch 3/5\n",
      "95/95 [==============================] - 240s 3s/step - loss: 0.0068 - accuracy: 0.9987 - val_loss: 0.0534 - val_accuracy: 0.9792\n",
      "Epoch 4/5\n",
      "95/95 [==============================] - 246s 3s/step - loss: 0.0024 - accuracy: 0.9993 - val_loss: 0.1171 - val_accuracy: 0.9822\n",
      "Epoch 5/5\n",
      "95/95 [==============================] - 220s 2s/step - loss: 0.0029 - accuracy: 0.9993 - val_loss: 0.0735 - val_accuracy: 0.9792\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import CSVLogger\n",
    "log = CSVLogger('log.csv', append=True, separator=',')\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(NB_WORDS, 3000, input_length=MAX_LEN))\n",
    "model.add(SpatialDropout1D(0.4))\n",
    "model.add(LSTM(704, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(352, activation='LeakyReLU'))\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics = ['accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "#Model Training\n",
    "history=model.fit(X_train_emb, y_train_emb,\n",
    "          epochs = 5,\n",
    "          batch_size=32,\n",
    "          validation_data = (X_valid_emb, y_valid_emb), \n",
    "          callbacks=[log],\n",
    "          verbose =1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 16s 452ms/step - loss: 0.0923 - accuracy: 0.9688\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.09232339262962341, 0.968805730342865]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test_seq_trunc,y_test_oh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001FA8C7075E8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "y_pred=model.predict(X_test_seq_trunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.9990392e-01, 3.1653057e-05],\n",
       "       [1.4522105e-02, 9.9250859e-01],\n",
       "       [6.3108206e-03, 9.9761081e-01],\n",
       "       ...,\n",
       "       [9.5831907e-01, 2.5483042e-02],\n",
       "       [3.6189377e-02, 9.7725940e-01],\n",
       "       [9.9948156e-01, 2.1079183e-04]], dtype=float32)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"company_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [28/Apr/2023 19:01:06] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001F9FDF72D38> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [28/Apr/2023 19:01:20] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [28/Apr/2023 19:01:44] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [28/Apr/2023 19:02:16] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [28/Apr/2023 19:02:28] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [28/Apr/2023 19:03:00] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [28/Apr/2023 19:03:19] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [28/Apr/2023 19:03:36] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask,request, render_template\n",
    "import numpy as np\n",
    "import keras\n",
    "\n",
    "\n",
    "app=Flask(__name__)\n",
    "\n",
    "model = keras.models.load_model(\"company_model.h5\")\n",
    "\n",
    "@app.route(\"/\")\n",
    "def home():\n",
    "    return render_template(\"index.html\")\n",
    "\n",
    "@app.route('/predict',methods=[\"POST\"])\n",
    "def predict():\n",
    "    text=request.form.get(\"company comment\")\n",
    "    \n",
    "    \n",
    "    text=preprocessing(text)\n",
    "    text=expand_contractions(text)\n",
    "    text=lemmatize_words(text)\n",
    "    \n",
    "    tk.fit_on_texts(X_train['lemma'])\n",
    "    t = tk.texts_to_sequences([text])\n",
    "    t=pad_sequences(t, maxlen=MAX_LEN)\n",
    "    ans=model.predict(t)\n",
    "    if ans[0][0]>ans[0][1]:\n",
    "        output=\"Positive Sentiment\"\n",
    "    else:\n",
    "        output=\"Negative sentiment\"\n",
    "        \n",
    "    \n",
    "    return render_template(\"index.html\" , pred=output)\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    app.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
